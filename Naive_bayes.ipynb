{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c34d57-2ea6-44ba-b033-a821b97b1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de389974-9444-49cd-97a1-4a3b171e76a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_5600\\2728658226.py:1: DtypeWarning: Columns (22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"fake_or_real_news.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: ['text', 'label', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29', 'Unnamed: 30', 'Unnamed: 31', 'Unnamed: 32', 'Unnamed: 33', 'Unnamed: 34', 'Unnamed: 35', 'Unnamed: 36', 'Unnamed: 37', 'Unnamed: 38', 'Unnamed: 39', 'Unnamed: 40', 'Unnamed: 41', 'Unnamed: 42', 'Unnamed: 43', 'Unnamed: 44', 'Unnamed: 45', 'Unnamed: 46', 'Unnamed: 47', 'Unnamed: 48', 'Unnamed: 49', 'Unnamed: 50', 'Unnamed: 51', 'Unnamed: 52', 'Unnamed: 53', 'Unnamed: 54', 'Unnamed: 55', 'Unnamed: 56', 'Unnamed: 57', 'Unnamed: 58', 'Unnamed: 59', 'Unnamed: 60', 'Unnamed: 61', 'Unnamed: 62', 'Unnamed: 63', 'Unnamed: 64', 'Unnamed: 65', 'Unnamed: 66', 'Unnamed: 67', 'Unnamed: 68', 'Unnamed: 69', 'Unnamed: 70', 'Unnamed: 71', 'Unnamed: 72', 'Unnamed: 73', 'Unnamed: 74', 'Unnamed: 75', 'Unnamed: 76', 'Unnamed: 77', 'Unnamed: 78', 'Unnamed: 79', 'Unnamed: 80', 'Unnamed: 81', 'Unnamed: 82', 'Unnamed: 83', 'Unnamed: 84', 'Unnamed: 85', 'Unnamed: 86', 'Unnamed: 87', 'Unnamed: 88', 'Unnamed: 89', 'Unnamed: 90', 'Unnamed: 91', 'Unnamed: 92', 'Unnamed: 93', 'Unnamed: 94', 'Unnamed: 95', 'Unnamed: 96', 'Unnamed: 97', 'Unnamed: 98', 'Unnamed: 99', 'Unnamed: 100', 'Unnamed: 101', 'Unnamed: 102', 'Unnamed: 103', 'Unnamed: 104', 'Unnamed: 105', 'Unnamed: 106', 'Unnamed: 107', 'Unnamed: 108', 'Unnamed: 109', 'Unnamed: 110', 'Unnamed: 111', 'Unnamed: 112', 'Unnamed: 113', 'Unnamed: 114', 'Unnamed: 115', 'Unnamed: 116', 'Unnamed: 117', 'Unnamed: 118', 'Unnamed: 119', 'Unnamed: 120', 'Unnamed: 121', 'Unnamed: 122', 'Unnamed: 123', 'Unnamed: 124', 'Unnamed: 125', 'Unnamed: 126', 'Unnamed: 127', 'Unnamed: 128', 'Unnamed: 129', 'Unnamed: 130', 'Unnamed: 131', 'Unnamed: 132', 'Unnamed: 133', 'Unnamed: 134', 'Unnamed: 135', 'Unnamed: 136', 'Unnamed: 137', 'Unnamed: 138']\n",
      "Cleaned file saved as 'cleaned_fake_or_real_news.csv'\n",
      "                                                text label\n",
      "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE\n",
      "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE\n",
      "2  U.S. Secretary of State John F. Kerry said Mon...  REAL\n",
      "3  â€” Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE\n",
      "4  It's primary day in New York and front-runners...  REAL\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"fake_or_real_news.csv\")\n",
    "print(\"Columns in the dataset:\", df.columns.tolist())\n",
    "df = df.rename(columns=lambda x: x.strip().lower())\n",
    "df = df[['text', 'label']]\n",
    "df.to_csv(\"cleaned_fake_or_real_news.csv\", index=False)\n",
    "print(\"Cleaned file saved as 'cleaned_fake_or_real_news.csv'\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddfa71d1-4b1e-4d28-82d1-2c147a64c78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "REAL    3161\n",
      "FAKE    3154\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df[df['label'].isin(['FAKE', 'REAL'])]\n",
    "df = df.reset_index(drop=True)\n",
    "print(df['label'].value_counts())\n",
    "df.to_csv(\"cleaned_file.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "011cca9c-a59d-4bad-9f31-112e7cde2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df[['text', 'label']]\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b9720b5-ca71-4052-a377-dd1f93998524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].map({'FAKE': 0, 'REAL': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccc5a441-b809-4273-aa1a-08016b7c51dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()                              \n",
    "    text = re.sub(r'http\\S+', '', text)              \n",
    "    text = re.sub(r'[^a-z\\s]', '', text)           \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()         \n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c696c392-b661-4683-96f6-08775e1f8556",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07620a0d-0b53-4d4d-acab-194a66b30f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_cv = vectorizer.fit_transform(X_train)\n",
    "X_test_cv = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9bd4fb8-5380-48ac-a68b-2baa27172581",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train_cv, y_train)\n",
    "y_pred = model.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6131ec6-9931-4659-aefe-01b21a6d84fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8701504354711006\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       616\n",
      "           1       0.89      0.85      0.87       647\n",
      "\n",
      "    accuracy                           0.87      1263\n",
      "   macro avg       0.87      0.87      0.87      1263\n",
      "weighted avg       0.87      0.87      0.87      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f0d44c-ea52-4aa7-b4fb-901902bbdc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model demonstrates high reliability and balanced predictive ability, effectively distinguishing between the two classes with an accuracy of 87%. The nearly equal precision, recall, and F1-scores across both categories suggest that the classifier is robust and generalizes well to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca5c302-52d6-4ddd-8436-027dc9ae62b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d8b986-5d9a-43fa-87a5-d8254b7aa42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df29c1-f381-41fb-818d-f50dea403269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4037749b-f406-4103-9592-a00cdf976b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad150d95-4755-4c7e-bf15-42509c9c109e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
